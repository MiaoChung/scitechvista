as.character  %>% strsplit(split='/', fixed=T) %>% unlist %>%
.[length(.)] %>% gsub("htm","")
xpathApply(res, "/html//div[@id='ctl00_oCPH_Left_oHGC_Upper_Page']//a[13]", xmlAttrs) %>%
as.character  %>% strsplit(split='/', fixed=T) %>% unlist %>%
.[length(.)] %>% sub("htm","")
xpathApply(res, "/html//div[@id='ctl00_oCPH_Left_oHGC_Upper_Page']//a[13]", xmlAttrs) %>%
as.character  %>% strsplit(split='/', fixed=T) %>% unlist %>%
.[length(.)] %>% strsplit(split='.', fixed=T)
xpathApply(res, "/html//div[@id='ctl00_oCPH_Left_oHGC_Upper_Page']//a[13]", xmlAttrs) %>%
as.character  %>% strsplit(split='/', fixed=T) %>% unlist %>%
.[length(.)] %>% strsplit(split='.', fixed=T)  %>% unlist %>% .[1]
xpathApply(res, "/html//div[@id='ctl00_oCPH_Left_oHGC_Upper_Page']//a[13]", xmlAttrs) %>%
as.character  %>% strsplit(split='/', fixed=T) %>% unlist %>%
.[length(.)] %>% strsplit(split='.', fixed=T)  %>% unlist %>% .[1] %>% as.numeric
finalpage = xpathApply(res, "/html//div[@id='ctl00_oCPH_Left_oHGC_Upper_Page']//a[13]", xmlAttrs) %>%
as.character  %>% strsplit(split='/', fixed=T) %>% unlist %>%
.[length(.)] %>% strsplit(split='.', fixed=T)  %>% unlist %>% .[1] %>% as.numeric
url
i=1
host= "https://scitechvista.most.gov.tw/zh-tw/Feature/L/0/13/10/"
url[i]=paste0(host, i, ".htm")
url
i=3
url[i]=paste0(host, i, ".htm")
url
for(i in 1:finalpage){
url[i]=paste0(host, i, ".htm")
res = GET(url[i])
reqText[i] = content(res, 'text', encoding='utf8')
}
reqText
data = xpathSApply(reqText,"//div/div/div[@class='box_title']/div/a", xmlValue)
reqText[1]
xpathSApply(reqText[1],"//div/div/div[@class='box_title']/div/a", xmlValue)
url[1]
xpathSApply(reqText[1],"/html//div[@class='box_topic']/a", xmlValue)
xpathApply
xpathApplyreqText[1]
reqText[1]
res = htmlParse(reqText[i], encoding = 'utf-8')
xpathSApply(res,"/html//div[@class='box_topic']/a", xmlValue)
xpathSApply(res,"/html//div[@class='box_topic']/a", xmlAttrbutes)
xpathSApply(res,"/html//div[@class='box_topic']/a", xmlAttrs)
for(i in 1:finalpage){
url[i]=paste0(host, i, ".htm")
res = GET(url[i])
reqText[i] = content(res, 'text', encoding='utf8')
res[i] = htmlParse(reqText[i], encoding = 'utf-8')
}
reqText[i] %>% htmlParse(encoding="utf8")
reqText[i] %>% htmlParse(encoding="utf8") %>%
xpathSApply("/html//div[@class='box_topic']/a", xmlAttrs)
length(reqText)
reqText[i] %>% htmlParse(encoding="utf8") %>%
xpathSApply("/html//div[@class='box_topic']/a", xmlAttrs)
data = reqText[i] %>% htmlParse(encoding="utf8") %>%
xpathSApply("/html//div[@class='box_topic']/a", xmlAttrs)
str(data)
View(data)
data[2,]
for(i in 1:finalpage){
res = htmlParse(reqText[i], encoding = 'utf-8')
data[i] = reqText[i] %>% htmlParse(encoding="utf8") %>%
xpathSApply("/html//div[@class='box_topic']/a", xmlAttrs) %>% .[2,]
}
warnings()
data
data=list()
for(i in 1:finalpage){
res = htmlParse(reqText[i], encoding = 'utf-8')
data[[i]] = reqText[i] %>% htmlParse(encoding="utf8") %>%
xpathSApply("/html//div[@class='box_topic']/a", xmlAttrs) %>% .[2,]
}
data[1]
data[41]
data[[1]][1]
strsplit(data[[1]][1],"/", fixed=T)
gsup(data[[1]][1],"../../../..", " ")
gsub(data[[1]][1],"../../../..", " ")
gsub( "../../../..", " ", data[[1]][1])
sub( "../../../..", " ", data[[1]][1])
data[[i]] = reqText[i] %>% htmlParse(encoding="utf8") %>%
xpathSApply("/html//div[@class='box_topic']/a", xmlAttrs) %>% .[2,] %>%
sub( "../../../..", "", data[[1]][1])
data[[i]] = reqText[i] %>% htmlParse(encoding="utf8") %>%
xpathSApply("/html//div[@class='box_topic']/a", xmlAttrs) %>% .[2,] %>%
sub( "../../../..", "", .[1])
data[[i]] = reqText[i] %>% htmlParse(encoding="utf8") %>%
xpathSApply("/html//div[@class='box_topic']/a", xmlAttrs) %>% .[2,]
reqText[i] %>% htmlParse(encoding="utf8") %>%
xpathSApply("/html//div[@class='box_topic']/a", xmlAttrs) %>% .[2,]
sapply(data, sub( "../../../..", "", .[1]))
sapply(data, sub( "../../../..", "", data[[i]][1]))
i=1
j=1
data[[i]][j]
lapply(data,FUN=sub( "../../../..", "", data[[i]][j]))
lapply(data,FUN=sub( "../../../..", ""))
lapply(data,FUN=sub( "../../../..", "", data))
for(i in 1:length(data)){
for(j in 1:10){
sub( "../../../..", "", data[[i]][j])
}
}
data[[1]]
for(i in 1:length(data)){
for(j in 1:10){
data[[i]][j] = sub( "../../../..", "", data[[i]][j])
}
}
data[[1]]
paste0( "https://scitechvista.most.gov.tw/zh-tw/Feature/",sub( "../../../..", "", data[[i]][j])  )
paste0( "https://scitechvista.most.gov.tw/zh-tw/Feature",sub( "../../../..", "", data[[i]][j])  )
data[[i]][j] = sub( "../../../..", "", data[[i]][j])
data[[i]][j]
data[[1]]
for(i in 1:length(data)){
for(j in 1:10){
data[[i]][j] = sub( "../../../..", "", data[[i]][j])
}
}
data
data=list()
for(i in 1:finalpage){
res = htmlParse(reqText[i], encoding = 'utf-8')
data[[i]] = reqText[i] %>% htmlParse(encoding="utf8") %>%
xpathSApply("/html//div[@class='box_topic']/a", xmlAttrs) %>% .[2,]
}
data2 = data
for(i in 1:length(data2)){
for(j in 1:10){
data2[[i]][j] = sub( "../../../..", "", data2[[i]][j])
}
}
data2
data2[[i]][j] = paste0("https://scitechvista.most.gov.tw/zh-tw/Feature/", data2[[i]][j])
data2
data2[[i]][j] = paste0("https://scitechvista.most.gov.tw/zh-tw/Feature", data2[[i]][j])
data2[[i]][j]
data2 = data
for(i in 1:length(data2)){
for(j in 1:10){
data2[[i]][j] = sub( "../../../..", "", data2[[i]][j])
data2[[i]][j] = paste0("https://scitechvista.most.gov.tw/zh-tw/Feature", data2[[i]][j])
}
}
data2
data2 = data
for(i in 1:length(data2)){
for(j in 1:10){
#     data2[[i]][j] = sub( "../../../..", "", data2[[i]][j])
data2[[i]][j] = paste0("https://scitechvista.most.gov.tw/zh-tw/Feature", sub( "../../../..", "", data2[[i]][j]))
}
}
data2
rm(data2)
rm(data)
data=list()
for(i in 1:finalpage){
res = htmlParse(reqText[i], encoding = 'utf-8')
data[[i]] = reqText[i] %>% htmlParse(encoding="utf8") %>%
xpathSApply("/html//div[@class='box_topic']/a", xmlAttrs) %>% .[2,]
}
for(i in 1:length(data)){
for(j in 1:10){
#     data2[[i]][j] = sub( "../../../..", "", data2[[i]][j])
data[[i]][j] = paste0("https://scitechvista.most.gov.tw/zh-tw/Feature", sub( "../../../..", "", data[[i]][j]))
}
}
data
data = data %>% unlist
length(data)
data=list()
for(i in 1:finalpage){
res = htmlParse(reqText[i], encoding = 'utf-8')
data[[i]] = reqText[i] %>% htmlParse(encoding="utf8") %>%
xpathSApply("/html//div[@class='box_topic']/a", xmlAttrs) %>% .[2,]
}
for(i in 1:length(data)){
for(j in 1:10){
data[[i]][j] = paste0("https://scitechvista.most.gov.tw/zh-tw/Feature", sub( "../../../..", "", data[[i]][j]))
}
}
data
data %<>% unlist
url = "https://scitechvista.most.gov.tw/zh-tw/Feature/C/0/13/10/41/150.htm"
res = GET(url)
res = content(res, 'text', encoding="utf8")
res = htmlParse(res, encoding = 'utf-8')
xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValues)
xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValue)
xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValue) %>%
unlist
author = data[2] %>% sub("\r\n\t\t\t\t\t\t\t\t\t","")
author
sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2])
res = GET(url)
url = "https://scitechvista.most.gov.tw/zh-tw/Feature/C/0/13/10/41/150.htm"
res = GET(url)
res = content(res, 'text', encoding="utf8")
res = htmlParse(res, encoding = 'utf-8')
data = xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValue) %>% unlist
sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2])
data[2] %>% sub("\r\n\t\t\t\t\t\t\t\t\t","")
res = GET(url)
res = content(res, 'text', encoding="utf8")
res = htmlParse(res, encoding = 'utf-8')
data = xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValue) %>% unlist
title = data[1]
data[2] %>% sub("\r\n\t\t\t\t\t\t\t\t\t","")
res = GET(url)
res = content(res, 'text', encoding="utf8")
res = htmlParse(res, encoding = 'utf-8')
data = xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValue) %>% unlist
data
data[2] %>% sub("\r\n\t\t\t\t\t\t\t\t\t","")
sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2])
sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2]) %>%
strsplit(split="|",fixed=T)
sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2]) %>%
strsplit(split="|",fixed=T) %>%
unlist %>%
.[1]
author = sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2]) %>%
strsplit(split="|",fixed=T) %>% unlist %>%  .[1]
data2 = sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2]) %>% strsplit(split="|",fixed=T) %>% unlist
data2
content= xpathApply(res, "/html//p", xmlValue)
content
substr(content, "日期：", "/")
content
substr(content, "日期：")
substr(content, "日期：", "[0-9$]")
content %<>% as.character
substr(content, "日期：", "[0-9$]")
content
substr(content, "日期：", "7")
substr(content, "日期："-1, "7")
substr(content, "電力"-1, "分配")
substr(content, "電力", "分配")
Start<-regexpr("日期：", CountryName)
Start<-regexpr("日期：", content)
Start
EndName<- regexpr("[0-9$]", content)
EndName
substr(content, Start, EndName)
regexpr("[0-9/]", content)
regexpr("[0-9/+]", content)
regexpr("0-9/+", content)
regexpr("^\d{4}[-/.]\d{1,2}[-/.]\d{1,2}$", content)
regexpr("^\d[-/.]\d{1,2}[-/.]\d{1,2}$", content)
regexpr("^\\d[-/.]\d{1,2}[-/.]\d{1,2}$", content)
regexpr("^\d{4}[-/.]\\d{1,2}[-/.]\\d{1,2}$", content)
regexpr("^\\d{4}[-/.]\\d{1,2}[-/.]\\d{1,2}$", content)
regexpr("\d{4}(?:/\d{1,2}){2}", content)
regexpr("^[201]", content)
regexpr("[201]", content)
regexpr("日期：", content)
EndName<- regexpr("[201\/]", content)
EndName<- regexpr("201\/", content)
EndName<- regexpr(" ^\d{4}(\-|\/|\.)\d{1,2}\1\d{1,2}$", content)
EndName<- regexpr("^\d{4}(\-|\/|\.)\d{1,2}\1\d{1,2}$", content)
EndName<- regexpr("[0-9]{4}/[0-9]{2}/[0-9]{2}", content)
EndName
regexpr("[0-9]{4}/[0-9]{2}/[0-9]{2}", content)
test_str <- c("2013/2/7", "你好啊", "\n")
grep('[0-9]{4}/[0-9]{2}/[0-9]{2}', test_str, value=TRUE, perl=TRUE)
grep('.', test_str, value=TRUE, perl=TRUE)
grep('[]0-9', test_str, value=TRUE, perl=TRUE)
grep('[0-9]', test_str, value=TRUE, perl=TRUE)
grep('\\d{4}/\\d{2}\\/\\d{2}\\', test_str, value=TRUE, perl=TRUE)
grep('\\d{4}/\\d{2}\\/\\d{2}', test_str, value=TRUE, perl=TRUE)
grep('\\d{4}/\\d{2}\\/\\d{2}', test_str, value=TRUE, perl=TRUE)
grep('[\d{4}/\d{2}/\d{2}]', test_str, value=TRUE, perl=TRUE)
grep('[\\d{4}/\\d{2}/\/\d{2}]', test_str, value=TRUE, perl=TRUE)
grep('\\d{4}/\\d{2}/\/\d{2}', test_str, value=TRUE, perl=TRUE)
grep('\\d{4}/\\d{2}/\\d{2}', test_str, value=TRUE, perl=TRUE)
grep('\\d{4}/\\d{1}/\\d{1}', test_str, value=TRUE, perl=TRUE)
grep('\\d{4}/\\d/\\d', test_str, value=TRUE, perl=TRUE)
regexpr("'\\d{4}/\\d/\\d'", content)
regexpr("'\\d/\\d/\\d'", content)
regexpr("\\d/\\d/\\d", content)
content= xpathApply(res, "/html//p", xmlValue)
Start<- regexpr("日期：", content)
EndName<- regexpr("\\d/\\d/\\d", content)
substr(content, Start, EndName)
substr(content, Start+5, EndName)
substr(content, Start+3, EndName)
substr(content, Start+3, EndName+5)
substr(content, Start+3, EndName+10)
date = substr(content, Start+3, EndName+10)
return(list("author"=author,
"unit"=unit,
"time"=time))
res = GET(url)
res = content(res, 'text', encoding="utf8")
res = htmlParse(res, encoding = 'utf-8')
data = xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValue) %>% unlist
title = data[1]
data2 = sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2]) %>% strsplit(split="|",fixed=T) %>% unlist
author = data2[1]
content= xpathApply(res, "/html//p", xmlValue)
Start<- regexpr("日期：", content)
unit = data2[2]
End<- regexpr("\\d/\\d/\\d", content)
time = substr(content, Start+3, End+10)
author
unit
time
author = data2[1] %>% gsub(" ","")
author
res = GET(url)
res = content(res, 'text', encoding="utf8")
res = htmlParse(res, encoding = 'utf-8')
data = xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValue) %>% unlist
title = data[1]
data2 = sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2]) %>% strsplit(split="|",fixed=T) %>% unlist
author = data2[1] %>% gsub(" ","")
data2
gsub(" ",".",data2[1])
gsub(" ","",data2[1])
author = data2[1] %>% gsub(" ","",.)
author
unit = data2[2] %>% gsub(" ","",.)
unit
data
data2
gsub("\n\t*", '', data2[1]))
gsub("\r\n\t*", '', data2[1]))
data2[1]
gsub("\r\n\t*", '', data2[2]))
gsub("\r+\n\t*", '', data2[2]))
GetPage = function(url){
res = GET(url)
res = content(res, 'text', encoding="utf8")
res = htmlParse(res, encoding = 'utf-8')
data = xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValue) %>% unlist
title = data[1]
data2 = sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2]) %>% strsplit(split="|",fixed=T) %>% unlist
author = data2[1] %>% gsub(" ","",.)
unit = data2[2] %>% gsub(" ","",.)
content= xpathApply(res, "/html//p", xmlValue)
Start<- regexpr("日期：", content)
End<- regexpr("\\d/\\d/\\d", content)
time = substr(content, Start+3, End+10)
return(list("author"=author, "unit"=unit, "time"=time))
}
data %<>% unlist
data
host= "https://scitechvista.most.gov.tw/zh-tw/Feature/L/0/13/10/"
for(i in 1:finalpage){
url[i]=paste0(host, i, ".htm")
res = GET(url[i])
reqText[i] = content(res, 'text', encoding='utf8')
}
data=list()
for(i in 1:finalpage){
res = htmlParse(reqText[i], encoding = 'utf-8')
data[[i]] = reqText[i] %>% htmlParse(encoding="utf8") %>%
xpathSApply("/html//div[@class='box_topic']/a", xmlAttrs) %>% .[2,]
}
for(i in 1:length(data)){
for(j in 1:10){
data[[i]][j] = paste0("https://scitechvista.most.gov.tw/zh-tw/Feature", sub( "../../../..", "", data[[i]][j]))
}
}
data %<>% unlist
data
table = lapply(data, GetPage)
res = GET(url)
res = content(res, 'text', encoding="utf8")
res = htmlParse(res, encoding = 'utf-8')
data = xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValue) %>% unlist
url = "https://scitechvista.most.gov.tw/zh-tw/Feature/C/0/13/10/41/150.htm"
res = GET(url)
res = content(res, 'text', encoding="utf8")
res = htmlParse(res, encoding = 'utf-8')
data = xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValue) %>% unlist
title = data[1]
data2 = sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2]) %>% strsplit(split="|",fixed=T) %>% unlist
author = data2[1] %>% gsub(" ","",.)
content= xpathApply(res, "/html//p", xmlValue)
End<- regexpr("\\d/\\d/\\d", content)
unit = data2[2] %>% gsub(" ","",.)
Start<- regexpr("日期：", content)
time = substr(content, Start+3, End+10)
table =cbind(author, unit, title, time)
table
table =cbind(author, unit, title, time) %>% as.data.frame
table
GetPage = function(url){
res = GET(url)
res = content(res, 'text', encoding="utf8")
res = htmlParse(res, encoding = 'utf-8')
data = xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValue) %>% unlist
title = data[1]
data2 = sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2]) %>% strsplit(split="|",fixed=T) %>% unlist
author = data2[1] %>% gsub(" ","",.)
unit = data2[2] %>% gsub(" ","",.)
content= xpathApply(res, "/html//p", xmlValue)
Start<- regexpr("日期：", content)
End<- regexpr("\\d/\\d/\\d", content)
time = substr(content, Start+3, End+10)
table =cbind(author, unit, title, time) %>% as.data.frame
return(table)
}
for(i in 1:finalpage){
url[i]=paste0("https://scitechvista.most.gov.tw/zh-tw/Feature/L/0/13/10/", i, ".htm")
res = GET(url[i])
reqText[i] = content(res, 'text', encoding='utf8')
}
data=list()
for(i in 1:finalpage){
res = htmlParse(reqText[i], encoding = 'utf-8')
data[[i]] = reqText[i] %>% htmlParse(encoding="utf8") %>%
xpathSApply("/html//div[@class='box_topic']/a", xmlAttrs) %>% .[2,]
}
for(i in 1:length(data)){
for(j in 1:10){
data[[i]][j] = paste0("https://scitechvista.most.gov.tw/zh-tw/Feature", sub( "../../../..", "", data[[i]][j]))
}
}
data %<>% unlist
GetPage = function(url){
res = GET(url)
res = content(res, 'text', encoding="utf8")
res = htmlParse(res, encoding = 'utf-8')
data = xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValue) %>% unlist
title = data[1]
data2 = sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2]) %>% strsplit(split="|",fixed=T) %>% unlist
author = data2[1] %>% gsub(" ","",.)
unit = data2[2] %>% gsub(" ","",.)
content= xpathApply(res, "/html//p", xmlValue)
Start<- regexpr("日期：", content)
End<- regexpr("\\d/\\d/\\d", content)
time = substr(content, Start+3, End+10)
table =cbind(author, unit, title, time) %>% as.data.frame
return(table)
}
table = lapply(data, GetPage)
data[1:3]
table = lapply(data[1:3], GetPage)
table
table = lapply(data[1:3], GetPage) %>% unlist
table
lapply(data[1:3], GetPage) %>% unlist
table = lapply(data[1:3], GetPage)
table = lapply(data[1:3], GetPage)
table
?do.call
lapply(data[1:3], GetPage) %>% do.call(rbind)
lapply(data[1:3], GetPage) %>% do.call(rbind.,)
lapply(data[1:3], GetPage) %>% do.call(rbind,.)
table = lapply(data, GetPage) %>% do.call(rbind,.)
View(table)
setwd("~/Dropbox/practice/crawler/scitechvista")
setwd("~/Dropbox/practice/crawler/scitechvista")
setwd("~/Dropbox/practice/crawler/scitechvista")
setwd("~/Dropbox/practice/crawler/scitechvista")
write.csv(table, "data.csv", header=TRUE)
write.csv(table, "data.csv")
GetPage = function(url){
res = GET(url)
res = content(res, 'text', encoding="utf8")
res = htmlParse(res, encoding = 'utf-8')
data = xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValue) %>% unlist
title = data[1]
data2 = sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2]) %>% strsplit(split="|",fixed=T) %>% unlist
author = data2[1] %>% gsub(" ","",.)
unit = data2[2] %>% gsub(" ","",.)
content= xpathApply(res, "/html//p", xmlValue)
Start<- regexpr("日期：", content)
End<- regexpr("\\d/\\d/\\d", content)
time = substr(content, Start+3, End+10)
table =cbind(author, unit, title, time, url) %>% as.data.frame
return(table)
}
table = lapply(data, GetPage) %>% do.call(rbind,.)
write.csv(table, "data.csv")
url = "https://scitechvista.most.gov.tw/zh-tw/Feature/C/0/13/10/2/2191.htm"
GetPage(url)
table = lapply(data, GetPage) %>% do.call(rbind,.)
table = lapply(data, GetPage) %>% do.call(rbind,.)
GetPage(url)
res = GET(url)
res = content(res, 'text', encoding="utf8")
res = htmlParse(res, encoding = 'utf-8')
data = xpathApply(res, "/html//div[@class='sub_headline']/div/div/div", xmlValue) %>% unlist
data
title = data[1]
title
data2 = sub("\r\n\t\t\t\t\t\t\t\t\t","", data[2]) %>% strsplit(split="|",fixed=T) %>% unlist
data2
author = data2[1] %>% gsub(" ","",.)
unit = data2[2] %>% gsub(" ","",.)
content= xpathApply(res, "/html//p", xmlValue)
content
content= xpathApply(res, "/html//div[@class='content']", xmlValue)
content
Start<- regexpr("日期：", content)
End<- regexpr("\\d/\\d/\\d", content)
time = substr(content, Start+3, End+10)
time
substr(content, Start+3, End+10) %>% gsub("\r\n\t*")
substr(content, Start+3, End+10) %>% gsub("\r\n\t*","",.)
url = "https://scitechvista.most.gov.tw/zh-tw/Feature/C/0/13/10/3/2163.htm"
table = lapply(data, GetPage) %>% do.call(rbind,.)
write.csv(table, "data.csv")
url = "https://scitechvista.most.gov.tw/zh-tw/Feature/C/0/13/10/3/2163.htm"
res=GET(url)
table = lapply(data, GetPage) %>% do.call(rbind,.)
url = "https://scitechvista.most.gov.tw/zh-tw/Feature/C/0/13/10/3/2163.htm"
